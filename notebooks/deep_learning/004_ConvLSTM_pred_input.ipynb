{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012f80e3-065f-4481-8b61-0b16c778386f",
   "metadata": {},
   "source": [
    "## generate previous frames with pCO2 and fit it against ConvLSTM\n",
    "\n",
    "### with 1 member + no socat mask best result:\n",
    "Full RMSE score:\n",
    "10.710741871844716\n",
    "SOCAT RMSE score:\n",
    "11.744262459251226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c497b4-9499-4832-aed7-d1c3b9d4b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n",
      "2023-09-09 17:31:10.453509: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64\n",
      "2023-09-09 17:31:10.453533: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray, custom_rmse\n",
    "\n",
    "sys.path.insert(0, '../../src/preprocess')\n",
    "from data_preprocess import preprocess_image_reduced,preprocess_images_nfp, inverse_scale_frame\n",
    "from data_preprocess import preprocess_images, inverse_scale_image, preprocess_image_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ea67d-8bc2-422f-8c39-0de87dd0ed5c",
   "metadata": {},
   "source": [
    "### Previous Frame generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa606ac5-b88d-4281-8e36-383af8d7b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/burg/glab/users/sk4973/venv2/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "ecCodes library not found using ['eccodes', 'libeccodes.so', 'libeccodes']\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#X1 = np.dstack((chl_images, mld_images, sss_images, sst_images, xco2_images))\u001b[39;00m\n\u001b[1;32m     43\u001b[0m X1 \u001b[38;5;241m=\u001b[39m X1\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m421\u001b[39m,\u001b[38;5;241m180\u001b[39m,\u001b[38;5;241m360\u001b[39m,\u001b[38;5;241m5\u001b[39m),order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m X_all \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m y_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((y_all, y1))\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dist_map = pd.read_csv(\"../../src/dist_map.csv\",header=None).to_numpy()\n",
    "dist_map = np.roll(np.fliplr(dist_map),180)\n",
    "dist_map = np.repeat(dist_map[np.newaxis, :, : ], 421, axis=0)\n",
    "\n",
    "def custom_rmse2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    custom_rmse(y_true, y_pred)\n",
    "    calculates root square mean value with focusing only on the ocean\n",
    "    + difference between sss\n",
    "    \"\"\"\n",
    "    idx  = tf.not_equal(y_true, 0.0)\n",
    "    idx2  = tf.equal(y_true, 0.0)\n",
    "    \n",
    "    y_pred1 = tf.boolean_mask(y_pred,idx)\n",
    "    y_true1 = tf.boolean_mask(y_true,idx)\n",
    "    y_true1 = tf.cast(y_true1, y_pred.dtype)\n",
    "    \n",
    "    \n",
    "    return rmse1\n",
    "\n",
    "# Reading Data\n",
    "dir = \"../../data/\"\n",
    "dir_name = \"../../data/member_001\"\n",
    "data_nums = [\"001\", \"002\", \"009\", \"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"020\",\n",
    "             \"021\", \"023\", \"024\", \"025\", \"030\", \"031\", \"034\", \"035\", \"101\", \"102\", \"103\", \"104\"]\n",
    "\n",
    "X_all = np.empty((0, 180, 360, 5))\n",
    "y_all = np.empty((0, 180, 360))\n",
    "\n",
    "for i in range(10):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    \n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    mld_images = preprocess_image_reduced(mld.MLD.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    y1 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    X1 = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images))\n",
    "    #X1 = np.dstack((chl_images, mld_images, sss_images, sst_images, xco2_images))\n",
    "    X1 = X1.reshape((421,180,360,5),order='F')\n",
    "    \n",
    "    X_all = np.concatenate((X_all, X1))\n",
    "    y_all = np.concatenate((y_all, y1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9daacc-057d-42cd-a84f-1a6d648d6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.00001, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627924f-1c6e-411a-9f59-e3d13dbe3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X_all[0].shape\n",
    "OUTPUT_SHAPE=y_all[0].shape\n",
    "\n",
    "INPUT_SHAPE, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19c52f6-2585-4067-9621-ff3e338de811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituting mld with dist_map\n",
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=5,activation='elu',\n",
    "                        padding=\"SAME\")\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=32, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=32),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "])\n",
    "\n",
    "myLearnRate=0.001\n",
    "custom_opt = tf.keras.optimizers.Adam(learning_rate=myLearnRate)\n",
    "\n",
    "\n",
    "base_model.compile(loss=custom_rmse, optimizer=custom_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a377ad5-1335-42eb-8244-0fb0167c74f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "264/264 [==============================] - 62s 210ms/step - loss: 340.9424 - val_loss: 82.9589\n",
      "Epoch 2/200\n",
      "264/264 [==============================] - 40s 151ms/step - loss: 82.9079 - val_loss: 81.3977\n",
      "Epoch 3/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 81.0197 - val_loss: 79.8382\n",
      "Epoch 4/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 79.5581 - val_loss: 78.2801\n",
      "Epoch 5/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 78.2317 - val_loss: 76.7233\n",
      "Epoch 6/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 76.5738 - val_loss: 75.1678\n",
      "Epoch 7/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 74.9713 - val_loss: 73.6135\n",
      "Epoch 8/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 73.6306 - val_loss: 72.0604\n",
      "Epoch 9/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 71.9212 - val_loss: 70.5086\n",
      "Epoch 10/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 70.5263 - val_loss: 68.9581\n",
      "Epoch 11/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 68.9474 - val_loss: 67.4090\n",
      "Epoch 12/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 67.2308 - val_loss: 65.8610\n",
      "Epoch 13/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 65.7020 - val_loss: 64.3144\n",
      "Epoch 14/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 64.3428 - val_loss: 62.7691\n",
      "Epoch 15/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 62.7583 - val_loss: 61.2254\n",
      "Epoch 16/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 61.0653 - val_loss: 59.6832\n",
      "Epoch 17/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 59.6850 - val_loss: 58.1423\n",
      "Epoch 18/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 58.0033 - val_loss: 56.6030\n",
      "Epoch 19/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 56.5620 - val_loss: 55.0652\n",
      "Epoch 20/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 55.1453 - val_loss: 53.5291\n",
      "Epoch 21/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 53.6272 - val_loss: 51.9946\n",
      "Epoch 22/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 51.9916 - val_loss: 50.4619\n",
      "Epoch 23/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 50.4966 - val_loss: 48.9314\n",
      "Epoch 24/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 49.0349 - val_loss: 47.4027\n",
      "Epoch 25/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 47.4655 - val_loss: 45.8759\n",
      "Epoch 26/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 45.9152 - val_loss: 44.3518\n",
      "Epoch 27/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 44.4859 - val_loss: 42.8298\n",
      "Epoch 28/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 42.7134 - val_loss: 41.3108\n",
      "Epoch 29/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 41.5497 - val_loss: 39.7956\n",
      "Epoch 30/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 39.8702 - val_loss: 38.2849\n",
      "Epoch 31/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 38.3782 - val_loss: 36.7791\n",
      "Epoch 32/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 36.8774 - val_loss: 35.2792\n",
      "Epoch 33/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 35.5316 - val_loss: 33.7877\n",
      "Epoch 34/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 34.0444 - val_loss: 32.3059\n",
      "Epoch 35/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 32.3412 - val_loss: 30.8371\n",
      "Epoch 36/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 31.0079 - val_loss: 29.3845\n",
      "Epoch 37/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 29.7776 - val_loss: 27.9540\n",
      "Epoch 38/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 28.2099 - val_loss: 26.5526\n",
      "Epoch 39/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 26.8260 - val_loss: 25.1878\n",
      "Epoch 40/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 25.3348 - val_loss: 23.8690\n",
      "Epoch 41/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 24.2108 - val_loss: 22.6110\n",
      "Epoch 42/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 23.0064 - val_loss: 21.4288\n",
      "Epoch 43/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 21.8476 - val_loss: 20.3367\n",
      "Epoch 44/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 20.5245 - val_loss: 19.3516\n",
      "Epoch 45/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 19.4796 - val_loss: 18.4856\n",
      "Epoch 46/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 18.7095 - val_loss: 17.7545\n",
      "Epoch 47/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 18.0677 - val_loss: 17.1595\n",
      "Epoch 48/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 17.3997 - val_loss: 16.6943\n",
      "Epoch 49/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 16.9214 - val_loss: 16.3495\n",
      "Epoch 50/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 16.5296 - val_loss: 16.1096\n",
      "Epoch 51/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 16.1110 - val_loss: 15.9505\n",
      "Epoch 52/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 16.1224 - val_loss: 15.8554\n",
      "Epoch 53/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8768 - val_loss: 15.8027\n",
      "Epoch 54/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8804 - val_loss: 15.7779\n",
      "Epoch 55/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.9121 - val_loss: 15.7679\n",
      "Epoch 56/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.9791 - val_loss: 15.7650\n",
      "Epoch 57/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8125 - val_loss: 15.7651\n",
      "Epoch 58/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.7909 - val_loss: 15.7661\n",
      "Epoch 59/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.9241 - val_loss: 15.7665\n",
      "Epoch 60/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8128 - val_loss: 15.7668\n",
      "Epoch 61/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8398 - val_loss: 15.7678\n",
      "Epoch 62/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8234 - val_loss: 15.7677\n",
      "Epoch 63/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.8203 - val_loss: 15.7683\n",
      "Epoch 64/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 15.8142 - val_loss: 15.7680\n",
      "Epoch 65/200\n",
      "264/264 [==============================] - 39s 147ms/step - loss: 15.7812 - val_loss: 15.7681\n",
      "Epoch 66/200\n",
      "264/264 [==============================] - 39s 148ms/step - loss: 15.8829 - val_loss: 15.7681\n",
      "Epoch 00066: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_path=\"../../models/base_model/cnn_final.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = base_model.fit(X_all,y_all, epochs=200, \n",
    "                         validation_data=(X_all,y_all),\n",
    "                         workers=-1,batch_size=16,\n",
    "                         callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e5ffcf-ac7f-4b45-a01a-2ddedbc6b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 21:51:30.487663: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-28 21:51:30.572286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-28 21:51:30.750947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 44.49GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-10-28 21:51:30.751035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-10-28 21:51:31.892971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-10-28 21:51:31.893035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-10-28 21:51:32.258250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-28 21:51:32.339543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-28 21:51:33.961466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-28 21:51:34.143274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-10-28 21:51:34.145361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-10-28 21:51:34.156562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-28 21:51:34.186518: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-28 21:51:34.205707: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-28 21:51:34.206641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 44.49GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-10-28 21:51:34.206664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-10-28 21:51:34.206675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-10-28 21:51:34.206683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-10-28 21:51:34.206691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-28 21:51:34.206699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-28 21:51:34.206706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-28 21:51:34.206714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-10-28 21:51:34.206722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-10-28 21:51:34.207046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-28 21:51:34.207466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-10-28 21:51:38.474650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-28 21:51:38.474678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-10-28 21:51:38.474687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-10-28 21:51:38.476670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42531 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n",
      "2022-10-28 21:51:45.500797: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-10-28 21:51:45.719453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900000000 Hz\n",
      "2022-10-28 21:51:47.913968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-10-28 21:52:51.650375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-10-28 21:52:54.536861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 80s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.models.load_model('../../models/base_model/cnn_final.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "predicted_image= cnn_model.predict(X_all,verbose=1)\n",
    "predicted_image[y_all==0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871ec4ac-7d0c-482a-8b1c-9a9e25c2d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_shapes: (4210, 180, 360) (4210, 180, 360)\n",
      "Full RMSE score:\n",
      "45.701713540243276\n"
     ]
    }
   ],
   "source": [
    "y_true_all = np.empty((0,180,360))\n",
    "y_pred_all = np.empty((0,180,360))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    tmp = i+1\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2t2 = read_xarray(dir_name,num =data_nums[i])\n",
    "    y_true,y_pred = inverse_scale_image(predicted_image[421*(tmp-1):421*tmp],pco2t2.pCO2.data)\n",
    "    y_true_all = np.concatenate((y_true_all, y_true))\n",
    "    y_pred_all = np.concatenate((y_pred_all, y_pred))\n",
    "\n",
    "\n",
    "print(\"y_shapes:\", y_true_all.shape, y_pred_all.shape)\n",
    "print(\"Full RMSE score:\")\n",
    "a=custom_rmse(y_pred_all,y_true_all)\n",
    "print(a.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f881b-211e-410a-8431-ce8d304e538e",
   "metadata": {},
   "source": [
    "### Using the prediction as input in ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ddf86-ab51-40c5-a699-a28f54f6d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2090, 3, 180, 360, 6), (2090, 3, 180, 360, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_conv = np.empty((0, 3, 180, 360, 6))\n",
    "y_all_conv = np.empty((0, 3, 180, 360, 1))\n",
    "X_index=np.lib.stride_tricks.sliding_window_view(range(421),3)\n",
    "\n",
    "tmp = 1\n",
    "\n",
    "for i in range(5):\n",
    "    dir_name = dir + \"member_\" + str(data_nums[i])\n",
    "    chl,mld,sss,sst,u10,xco2,icefrac,patm,pco2 = read_xarray(dir_name,num=data_nums[i])\n",
    "\n",
    "    chl_images = preprocess_image_reduced(chl.Chl.data)\n",
    "    sss_images = preprocess_image_reduced(sss.SSS.data)\n",
    "    sst_images = preprocess_image_reduced(sst.SST.data)\n",
    "    xco2_images = preprocess_image_reduced(xco2.XCO2.data,xco2=True)\n",
    "    pco2 = preprocess_image_reduced(pco2.pCO2.data)\n",
    "    dist_map = preprocess_image_reduced(dist_map)\n",
    "    \n",
    "    y = np.expand_dims(pco2[X_index][1:], axis=4)\n",
    "    \n",
    "    X = np.dstack((chl_images, dist_map, sss_images, sst_images, xco2_images,predicted_image[421*(tmp-1):421*tmp]))\n",
    "    tmp+=1\n",
    "    X = X.reshape((421,180,360,6),order='F')\n",
    "    X = X[X_index][:-1]\n",
    "    \n",
    "    X_all_conv = np.concatenate((X_all_conv, X))\n",
    "    y_all_conv = np.concatenate((y_all_conv, y))\n",
    "\n",
    "\n",
    "shuffle_ind = (np.arange(X_all_conv.shape[0]))\n",
    "np.random.shuffle(shuffle_ind)\n",
    "X_all_conv = np.array(X_all_conv)[shuffle_ind.astype(int)]\n",
    "y_all_conv = np.array(y_all_conv)[shuffle_ind.astype(int)]\n",
    "\n",
    "X_all_conv.shape, y_all_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8417f932-9170-4f2f-9ecd-4202f4df46a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 180, 360, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE=X_all_conv[0].shape\n",
    "OUTPUT_SHAPE=y_all_conv[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a006b6ce-e685-4e6e-acd7-866fd8927ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "DefaultConvLSTM2D = partial(keras.layers.ConvLSTM2D,\n",
    "                        filters=32, kernel_size=(5, 5),\n",
    "                        padding=\"same\",return_sequences=True,\n",
    "                        activation=\"elu\",)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConvLSTM2D(input_shape=INPUT_SHAPE),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(5,5)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(3,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConvLSTM2D(kernel_size=(1,1)),\n",
    "    keras.layers.Conv3D(filters = 1, kernel_size=(3,3,3),activation=\"elu\", padding=\"same\")\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_rmse, optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.99),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab102c5-0812-4c3b-ab10-93cc74b5f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "262/262 [==============================] - 374s 1s/step - loss: 38.3820 - val_loss: 22.9248\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 366s 1s/step - loss: 9.9264 - val_loss: 10.7404\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 346s 1s/step - loss: 8.8418 - val_loss: 8.2187\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 338s 1s/step - loss: 8.1022 - val_loss: 8.9758\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 337s 1s/step - loss: 7.1808 - val_loss: 7.5352\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 6.5682"
     ]
    }
   ],
   "source": [
    "model_path=\"../../models/ConvLSTM_final.h5\"\n",
    "\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "\n",
    "# Fit the model to the training data.\n",
    "hist = model.fit(\n",
    "    X_all_conv,\n",
    "    y_all_conv,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_all_conv,y_all_conv),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afda7f-254d-4dba-897e-48624c90e4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594925c-d5b1-4335-bf58-9bd4094439c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
