{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications\n",
    "\n",
    "Link to Interactive Notebook: \n",
    "https://colab.research.google.com/drive/1sbJTsgCsAQwCkGdLXK7EdgkaTpiTGBM1#scrollTo=T71qxHyh9p23\n",
    "\n",
    "1. Reduced Input Dimension\n",
    "2. Different handling of xco2\n",
    "3. Custom rmse function\n",
    "\n",
    "What has helped the most?\n",
    "- ELU\n",
    "- ADAM\n",
    "- MODEL Architecture\n",
    "\n",
    "batch size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "from utils import df_to_xarray,read_xarray,inverse_scale_image, get_point_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "dir_name=\"../../data/data1\"\n",
    "val_dir_name=\"../../data/data2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../src/preprocess')\n",
    "\n",
    "from data_preprocess import preprocess_images\n",
    "\n",
    "X, pco2_images = preprocess_images(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=X[0].shape\n",
    "OUTPUT_SHAPE=pco2_images[0].shape\n",
    "\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pco2_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pco2_images[1],cmap=\"RdBu\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Image Segmentation\n",
    "CNN - Unet\n",
    "\n",
    "Reference: \n",
    "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../src')\n",
    "from utils import df_to_xarray,read_xarray, custom_rmse\n",
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=5,activation='elu',\n",
    "                        padding=\"SAME\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3), #pool size 3 > pool size 2\n",
    "    keras.layers.Dropout(0.3),# drop out at the end of the deepest\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "\n",
    "\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),    \n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "## BEST SO FAR ##\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLearnRate=0.001\n",
    "custom_opt = tf.keras.optimizers.Adam(learning_rate=myLearnRate)\n",
    "base_model.compile(loss=custom_rmse, optimizer=custom_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../models/base_model/base_model_new.h5\"\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "#batch size 24, 32, 64 not as good\n",
    "# batch size 16 the best\n",
    "history = base_model.fit(X,pco2_images, epochs=100, validation_data=(X,pco2_images),workers=-1,batch_size=16,callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = tf.keras.models.load_model('../models/base_model/base_model_new.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "predicted_image=best_model.predict(X,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image[pco2_images==0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, 2,figsize=(12, 6))\n",
    "\n",
    "\n",
    "img=axis[0][0].imshow(np.flipud(predicted_image[0]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "axis[0][0].set_title(\"prediction\")\n",
    "plt.colorbar(img,ax=axis)\n",
    "\n",
    "img1=axis[0][1].imshow(np.flipud(pco2_images[0]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "axis[0][1].set_title(\"true\")\n",
    "\n",
    "diff=np.flipud(np.squeeze(predicted_image[0]-pco2_images[0]))\n",
    "img2=axis[1][0].imshow(diff,cmap=\"RdBu\", interpolation=\"nearest\")\n",
    "axis[1][0].set_title(\"residual\")\n",
    "plt.colorbar(img2,ax=axis)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('../assets/cnn-unet.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import imageio\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "d = predicted_image - pco2_images\n",
    "\n",
    "norm = mcolors.TwoSlopeNorm(vmin=d.min(), vmax = d.max(), vcenter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for i in range(421):\n",
    "    # plot the line chart\n",
    "    figure, axis = plt.subplots(2, 2,figsize=(12, 6))\n",
    "\n",
    "    img=axis[0][0].imshow(np.flipud(predicted_image[i]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "    axis[0][0].set_title(\"prediction\")\n",
    "    plt.colorbar(img,ax=axis)\n",
    "\n",
    "    img1=axis[0][1].imshow(np.flipud(pco2_images[i]),cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "    axis[0][1].set_title(\"true\")\n",
    "\n",
    "    diff=np.flipud(np.squeeze(predicted_image[i]-pco2_images[i]))\n",
    "    img2=axis[1][0].imshow(diff,cmap=\"RdBu\", interpolation=\"nearest\",norm=norm)\n",
    "    axis[1][0].set_title(\"residual\")\n",
    "    plt.colorbar(img2,ax=axis)\n",
    "    \n",
    "    # create file name and append it to a list\n",
    "    filename = f'{i}.png'\n",
    "    filenames.append(filename)\n",
    "    \n",
    "    # save frame\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "# build gif\n",
    "with imageio.get_writer('../assets/cnn-unet.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        \n",
    "# Remove files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "\n",
    "for i in range(421):    \n",
    "    rmse = np.sqrt(np.mean((pco2_images[i]-predicted_image)**2))\n",
    "    rmses.append(rmse)\n",
    "    \n",
    "plt.plot(rmses)\n",
    "plt.savefig('../assets/unet-overtime.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "- more complex model with a greater parameters\n",
    "- need a different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#kernel_size matters, 2 does not work\n",
    "\n",
    "model1 = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=32, input_shape=INPUT_SHAPE),\n",
    "    DefaultConv2D(filters=32),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.35),\n",
    "\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=3),\n",
    "    keras.layers.Dropout(0.35),\n",
    "\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "\n",
    "    keras.layers.UpSampling2D(size=3),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=2),\n",
    "    DefaultConv2D(filters=1,kernel_size=1),\n",
    "    keras.layers.Reshape(OUTPUT_SHAPE)\n",
    "   \n",
    "])\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLearnRate=0.001\n",
    "custom_opt = tf.keras.optimizers.Adam(learning_rate=myLearnRate)\n",
    "model1.compile(loss=custom_rmse, optimizer=custom_opt, metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../models/base_model/reduceddim_model1.h5\"\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]\n",
    "\n",
    "history = model1.fit(X,pco2_images, epochs=100, validation_data=(X,pco2_images),workers=-1,batch_size=16,callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = tf.keras.models.load_model('../models/base_model/reduceddim_model1.h5', custom_objects={'custom_rmse':custom_rmse})\n",
    "predicted_image=best_model.predict(X,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "img=axis[0].imshow(np.flipud(np.squeeze(predicted_image[1])), cmap=\"RdBu\", interpolation=\"nearest\")\n",
    "axis[0].set_title(\"prediction\")\n",
    "plt.colorbar(img,ax=axis)\n",
    "\n",
    "img1=axis[1].imshow(np.flipud(np.squeeze(pco2_images[419:421][1])), cmap=\"RdBu\", interpolation=\"nearest\")\n",
    "axis[1].set_title(\"true\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=np.flipud(np.squeeze(pco2_images[419:421][1]-predicted_image[1]))\n",
    "plt.imshow(diff,cmap=\"RdBu\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Residual Plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over time\n",
    "\n",
    "rmses = []\n",
    "\n",
    "for i in range(421):    \n",
    "    rmse = np.sqrt(np.mean((pco2_images[i]-predicted_image)**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rmses)\n",
    "plt.savefig('../assets/overtime.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting PCO2 Prediction per Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scale_image(arr, df):\n",
    "    \"\"\"\n",
    "    inverse_scale_image(arr, df):\n",
    "    - inverses the pco2 scaling\n",
    "    \"\"\"\n",
    "    \n",
    "    old_min = np.nanmin(df)\n",
    "    old_max = np.nanmax(df)\n",
    "\n",
    "    y_pred = arr*(old_max-old_min)/255+old_min\n",
    "    \n",
    "    y_true=np.nan_to_num(df)\n",
    "    y_pred[y_true==0]=0\n",
    "    return y_true,y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl,mld,sss,sst,u10,fg_co2,xco2,icefrac,patm,pco2 = read_xarray(dir_name)\n",
    "\n",
    "y_true,y_pred = inverse_scale_image(predicted_image,pco2.pCO2.data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaled back RMSE score:\")\n",
    "np.sqrt(np.mean((y_true-y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
